# Jailbreak and Toxicity Collection
1. LLM & RL & VLM & Diffusion Model & Agent & Robot
2. Jailbreak Attack & Defense
3. Safety：Overall Safety、Toxicity（**毒性是安全性的一个具体维度，而安全性包含更广泛的风险。**）、Bias


## model classification
|             Category             | Number |
| :------------------------------: | :----: |
|       Large Language Model       |        |
| Multi-model Large Language Model |        |
|         Diffusion Model          |        |
|           Agent&Robot            |        |
|      Large Reasoning Model       |        |

