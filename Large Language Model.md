# Large Language Model
### Jailbreak Attack & Defense
#### Jailbreak Attack


#### Jailbreak Defense



### Toxicity Analysis & Detoxicity
#### Toxicity Analysis
- 【2025-01】[How Toxic Can You Get? Search-based Toxicity Testing for Large Language Models](https://arxiv.org/abs/2501.01741)
  <details>
    
    <summary>点击：具体介绍</summary>
    
    > - **Info**: arXiv:2501.01741 (cs)
    > - **Authors**:
    > - **Institutions**:
    > - **Content**:
  

- 【2024-12】 [Toxicity Detection towards Adaptability to Changing Perturbations](https://arxiv.org/abs/2412.15267)

- 【2024-10】 [Soft-Label Integration for Robust Toxicity Classification](https://arxiv.org/abs/2410.14894)


#### Detoxicity
